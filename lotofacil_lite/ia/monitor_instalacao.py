#!/usr/bin/env python3
"""
Monitor de InstalaÃ§Ã£o - LotoScope AI
Monitora o progresso da instalaÃ§Ã£o dos modelos
"""

import subprocess
import time
import sys
import os

def check_ollama_path():
    """Encontra o caminho do Ollama"""
    possivel_paths = [
        f"C:\\Users\\{os.environ.get('USERNAME', '')}\\AppData\\Local\\Programs\\Ollama\\ollama.exe",
        "C:\\Program Files\\Ollama\\ollama.exe",
        "ollama"
    ]
    
    for path in possivel_paths:
        try:
            if path != "ollama" and not os.path.exists(path):
                continue
            
            result = subprocess.run([path, "--version"], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                return path
        except:
            continue
    
    return None

def list_models(ollama_path):
    """Lista modelos instalados"""
    try:
        result = subprocess.run([ollama_path, "list"], 
                              capture_output=True, text=True, timeout=10)
        if result.returncode == 0:
            return result.stdout
        return None
    except Exception as e:
        return f"Erro: {e}"

def check_server_status():
    """Verifica se servidor estÃ¡ rodando"""
    try:
        import requests
        response = requests.get("http://localhost:11434/api/tags", timeout=3)
        return response.status_code == 200
    except:
        return False

def main():
    print("ğŸ” MONITOR DE INSTALAÃ‡ÃƒO - LOTOSCOPE AI")
    print("="*50)
    
    # Encontrar Ollama
    ollama_path = check_ollama_path()
    if not ollama_path:
        print("âŒ Ollama nÃ£o encontrado!")
        return
    
    print(f"âœ… Ollama encontrado em: {ollama_path}")
    
    # Verificar servidor
    server_running = check_server_status()
    print(f"ğŸ–¥ï¸  Servidor: {'âœ… Rodando' if server_running else 'âŒ Parado'}")
    
    if not server_running:
        print("\nâš ï¸  Para iniciar o servidor, execute:")
        print(f"   {ollama_path} serve")
    
    # Listar modelos
    print(f"\nğŸ§  Modelos instalados:")
    models_output = list_models(ollama_path)
    
    if models_output:
        lines = models_output.strip().split('\n')
        if len(lines) > 1:  # Tem header + modelos
            for line in lines[1:]:  # Pular header
                if line.strip():
                    print(f"   âœ… {line}")
        else:
            print("   âš ï¸  Nenhum modelo instalado ainda")
    
    # Verificar modelo especÃ­fico
    required_models = ["llama3:8b", "llama3:latest"]
    
    print(f"\nğŸ¯ Modelos necessÃ¡rios para LotoScope AI:")
    for model in required_models:
        if models_output and model in models_output:
            print(f"   âœ… {model}")
        else:
            print(f"   âŒ {model} - Execute: {ollama_path} pull {model}")
    
    # Status geral
    models_ok = models_output and any(model in models_output for model in required_models)
    
    print(f"\nğŸ“Š STATUS GERAL:")
    print(f"   Ollama:    {'âœ…' if ollama_path else 'âŒ'}")
    print(f"   Servidor:  {'âœ…' if server_running else 'âŒ'}")
    print(f"   Modelos:   {'âœ…' if models_ok else 'âŒ'}")
    
    if ollama_path and server_running and models_ok:
        print("\nğŸ‰ SISTEMA PRONTO!")
        print("   Execute: python lotoscope_ai_chat.py")
        
        # Oferecer teste rÃ¡pido
        test = input("\nğŸ§ª Fazer teste rÃ¡pido? (s/n): ").lower().strip()
        if test in ['s', 'sim', 'y', 'yes']:
            print("\nğŸ”„ Testando...")
            try:
                import sys
                sys.path.insert(0, '.')
                from lotoscope_ai_assistant import LotoScopeAIAssistant
                
                assistant = LotoScopeAIAssistant()
                status_ok, status_msg = assistant.check_ollama_status()
                print(f"ğŸ“Š Status: {status_msg}")
                
                if status_ok:
                    print("ğŸ¤– Fazendo pergunta teste...")
                    resposta = assistant.responder("OlÃ¡! VocÃª consegue me ajudar?")
                    print(f"ğŸ’¬ Resposta: {resposta[:100]}...")
                    print("âœ… TESTE APROVADO!")
                
            except Exception as e:
                print(f"âŒ Erro no teste: {e}")
    
    else:
        print("\nâš ï¸  SISTEMA AINDA NÃƒO ESTÃ PRONTO")
        if not server_running:
            print(f"1. Inicie o servidor: {ollama_path} serve")
        if not models_ok:
            print(f"2. Instale modelo: {ollama_path} pull llama3:8b")

if __name__ == "__main__":
    main()
