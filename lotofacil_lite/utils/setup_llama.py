#!/usr/bin/env python3
"""
LotoScope AI Setup - Instalador Automatizado do Llama
Instala e configura o assistente IA local automaticamente
"""

import os
import sys
import subprocess
import urllib.request
import zipfile
import shutil
import json
import time
from pathlib import Path
import platform

class LlamaSetupInstaller:
    """Instalador automatizado do Llama para LotoScope"""
    
    def __init__(self):
        self.system = platform.system().lower()
        self.architecture = platform.machine().lower()
        self.project_root = Path(__file__).parent
        self.downloads_dir = self.project_root / "downloads"
        self.ollama_installed = False
        
        # URLs de download
        self.ollama_urls = {
            "windows": {
                "x86_64": "https://ollama.ai/download/OllamaSetup.exe",
                "amd64": "https://ollama.ai/download/OllamaSetup.exe"
            }
        }
        
        # Modelos recomendados
        self.recommended_models = [
            {"name": "llama3:8b", "size": "4.7GB", "ram": "8GB", "description": "RÃ¡pido, boa qualidade"},
            {"name": "llama3:70b", "size": "40GB", "ram": "32GB", "description": "Muito preciso, lento"},
            {"name": "codellama:13b", "size": "7.3GB", "ram": "16GB", "description": "Especializado em cÃ³digo"}
        ]
    
    def print_header(self):
        """CabeÃ§alho do instalador"""
        print("ğŸš€" + "="*60 + "ğŸš€")
        print("    LOTOSCOPE AI SETUP - INSTALADOR AUTOMÃTICO")
        print("ğŸš€" + "="*60 + "ğŸš€")
        print("ğŸ¤– InstalaÃ§Ã£o automatizada do Llama Local")
        print("ğŸ¯ Especializado para anÃ¡lise de loterias")
        print("ğŸ”’ 100% Privado - sem envio de dados")
        print("-" * 62)
    
    def check_system_requirements(self):
        """Verifica requisitos do sistema"""
        print("ğŸ” VERIFICANDO REQUISITOS DO SISTEMA...")
        
        requirements = {
            "os": {"status": False, "info": ""},
            "ram": {"status": False, "info": ""},
            "disk": {"status": False, "info": ""},
            "python": {"status": False, "info": ""},
            "internet": {"status": False, "info": ""}
        }
        
        # Verificar SO
        if self.system == "windows":
            requirements["os"]["status"] = True
            requirements["os"]["info"] = f"âœ… {platform.system()} {platform.release()}"
        else:
            requirements["os"]["info"] = f"âŒ SO nÃ£o suportado: {platform.system()}"
        
        # Verificar RAM
        try:
            import psutil
            ram_gb = psutil.virtual_memory().total / (1024**3)
            if ram_gb >= 8:
                requirements["ram"]["status"] = True
                requirements["ram"]["info"] = f"âœ… {ram_gb:.1f}GB RAM disponÃ­vel"
            else:
                requirements["ram"]["info"] = f"âš ï¸ {ram_gb:.1f}GB RAM (recomendado: 16GB+)"
        except ImportError:
            requirements["ram"]["info"] = "âš ï¸ NÃ£o foi possÃ­vel verificar RAM"
        
        # Verificar espaÃ§o em disco
        try:
            disk_free = shutil.disk_usage(self.project_root).free / (1024**3)
            if disk_free >= 20:
                requirements["disk"]["status"] = True
                requirements["disk"]["info"] = f"âœ… {disk_free:.1f}GB livres"
            else:
                requirements["disk"]["info"] = f"âŒ {disk_free:.1f}GB livres (precisa 20GB+)"
        except:
            requirements["disk"]["info"] = "âš ï¸ NÃ£o foi possÃ­vel verificar espaÃ§o"
        
        # Verificar Python
        if sys.version_info >= (3, 8):
            requirements["python"]["status"] = True
            requirements["python"]["info"] = f"âœ… Python {sys.version.split()[0]}"
        else:
            requirements["python"]["info"] = f"âŒ Python {sys.version.split()[0]} (precisa 3.8+)"
        
        # Verificar internet
        try:
            urllib.request.urlopen('https://ollama.ai', timeout=5)
            requirements["internet"]["status"] = True
            requirements["internet"]["info"] = "âœ… ConexÃ£o com internet OK"
        except:
            requirements["internet"]["info"] = "âŒ Sem conexÃ£o com internet"
        
        # Mostrar resultados
        print("\nğŸ“‹ REQUISITOS:")
        for req, data in requirements.items():
            print(f"   {data['info']}")
        
        # Verificar se pode continuar
        critical_reqs = ["os", "disk", "python", "internet"]
        can_continue = all(requirements[req]["status"] for req in critical_reqs)
        
        if not can_continue:
            print("\nâŒ REQUISITOS CRÃTICOS NÃƒO ATENDIDOS!")
            print("ğŸ’¡ Resolva os problemas acima antes de continuar")
            return False
        
        print("\nâœ… REQUISITOS OK - Pode continuar a instalaÃ§Ã£o!")
        return True
    
    def check_ollama_installed(self):
        """Verifica se Ollama jÃ¡ estÃ¡ instalado"""
        try:
            result = subprocess.run(['ollama', '--version'], 
                                  capture_output=True, text=True, timeout=10)
            if result.returncode == 0:
                version = result.stdout.strip()
                print(f"âœ… Ollama jÃ¡ instalado: {version}")
                self.ollama_installed = True
                return True
        except (FileNotFoundError, subprocess.TimeoutExpired):
            pass
        
        print("â„¹ï¸ Ollama nÃ£o encontrado - serÃ¡ instalado")
        return False
    
    def download_ollama(self):
        """Baixa o instalador do Ollama"""
        if self.ollama_installed:
            return True
        
        print("\nğŸ“¥ BAIXANDO OLLAMA...")
        
        # Criar diretÃ³rio de downloads
        self.downloads_dir.mkdir(exist_ok=True)
        
        # URL para Windows
        if self.system != "windows":
            print("âŒ InstalaÃ§Ã£o automÃ¡tica sÃ³ disponÃ­vel para Windows")
            print("ğŸ’¡ Instale manualmente: https://ollama.ai/download")
            return False
        
        url = self.ollama_urls["windows"]["x86_64"]
        installer_path = self.downloads_dir / "OllamaSetup.exe"
        
        try:
            print(f"ğŸŒ Baixando de: {url}")
            print("â³ Isso pode demorar alguns minutos...")
            
            def progress_hook(block_num, block_size, total_size):
                if total_size > 0:
                    percent = (block_num * block_size / total_size) * 100
                    print(f"\rğŸ“Š Progresso: {percent:.1f}%", end="", flush=True)
            
            urllib.request.urlretrieve(url, installer_path, progress_hook)
            print(f"\nâœ… Download concluÃ­do: {installer_path}")
            return True
            
        except Exception as e:
            print(f"\nâŒ Erro no download: {e}")
            print("ğŸ’¡ Baixe manualmente: https://ollama.ai/download")
            return False
    
    def install_ollama(self):
        """Instala o Ollama"""
        if self.ollama_installed:
            return True
        
        print("\nâš™ï¸ INSTALANDO OLLAMA...")
        
        installer_path = self.downloads_dir / "OllamaSetup.exe"
        
        if not installer_path.exists():
            print("âŒ Instalador nÃ£o encontrado")
            return False
        
        try:
            print("ğŸš€ Executando instalador...")
            print("ğŸ’¡ Siga as instruÃ§Ãµes na tela do instalador")
            
            # Executar instalador
            process = subprocess.Popen([str(installer_path)], 
                                     shell=True)
            process.wait()
            
            print("âœ… InstalaÃ§Ã£o do Ollama concluÃ­da")
            
            # Verificar se foi instalado
            time.sleep(5)  # Aguardar um pouco
            
            if self.check_ollama_installed():
                return True
            else:
                print("âš ï¸ Ollama pode precisar de reinicializaÃ§Ã£o")
                print("ğŸ’¡ Reinicie o terminal e execute novamente")
                return False
                
        except Exception as e:
            print(f"âŒ Erro na instalaÃ§Ã£o: {e}")
            return False
    
    def list_available_models(self):
        """Lista modelos disponÃ­veis"""
        print("\nğŸ§  MODELOS DISPONÃVEIS:")
        print("-" * 50)
        
        for i, model in enumerate(self.recommended_models, 1):
            print(f"{i}. {model['name']}")
            print(f"   ğŸ“¦ Tamanho: {model['size']}")
            print(f"   ğŸ§® RAM mÃ­n: {model['ram']}")  
            print(f"   ğŸ“ {model['description']}")
            print()
    
    def install_model(self, model_name):
        """Instala modelo especÃ­fico"""
        print(f"\nğŸ¤– INSTALANDO MODELO: {model_name}")
        print("â³ Isso pode demorar MUITO tempo...")
        print("ğŸ’¡ O download pode ser de vÃ¡rios GB")
        
        try:
            process = subprocess.Popen(['ollama', 'pull', model_name],
                                     stdout=subprocess.PIPE,
                                     stderr=subprocess.STDOUT,
                                     text=True,
                                     universal_newlines=True)
            
            # Mostrar progresso em tempo real
            while True:
                output = process.stdout.readline()
                if output == '' and process.poll() is not None:
                    break
                if output:
                    print(f"ğŸ“Š {output.strip()}")
            
            if process.returncode == 0:
                print(f"âœ… Modelo {model_name} instalado com sucesso!")
                return True
            else:
                print(f"âŒ Erro ao instalar modelo {model_name}")
                return False
                
        except Exception as e:
            print(f"âŒ Erro: {e}")
            return False
    
    def test_installation(self, model_name):
        """Testa a instalaÃ§Ã£o"""
        print(f"\nğŸ§ª TESTANDO INSTALAÃ‡ÃƒO COM {model_name}...")
        
        try:
            # Testar comando bÃ¡sico
            test_prompt = "Responda apenas: 'OlÃ¡, sou o LotoScope AI Assistant!'"
            
            process = subprocess.Popen(['ollama', 'run', model_name],
                                     stdin=subprocess.PIPE,
                                     stdout=subprocess.PIPE,
                                     stderr=subprocess.PIPE,
                                     text=True)
            
            output, error = process.communicate(input=test_prompt, timeout=30)
            
            if "LotoScope" in output or "OlÃ¡" in output:
                print("âœ… TESTE BEM-SUCEDIDO!")
                print(f"ğŸ¤– Resposta: {output[:100]}...")
                return True
            else:
                print("âš ï¸ Teste parcialmente bem-sucedido")
                print(f"ğŸ¤– Resposta: {output[:100]}...")
                return True
                
        except subprocess.TimeoutExpired:
            print("âš ï¸ Teste demorou muito - mas instalaÃ§Ã£o OK")
            return True
        except Exception as e:
            print(f"âŒ Erro no teste: {e}")
            return False
    
    def install_python_dependencies(self):
        """Instala dependÃªncias Python"""
        print("\nğŸ“¦ INSTALANDO DEPENDÃŠNCIAS PYTHON...")
        
        dependencies = ['psutil', 'requests', 'pathlib-extensions']
        
        for dep in dependencies:
            try:
                print(f"ğŸ“¥ Instalando {dep}...")
                subprocess.check_call([sys.executable, '-m', 'pip', 'install', dep])
                print(f"âœ… {dep} instalado")
            except subprocess.CalledProcessError:
                print(f"âš ï¸ Erro ao instalar {dep}")
    
    def create_shortcuts(self):
        """Cria atalhos para facilitar uso"""
        print("\nğŸ”— CRIANDO ATALHOS...")
        
        # Script de inicializaÃ§Ã£o rÃ¡pida
        quick_start_script = f"""@echo off
cd /d "{self.project_root}"
echo ğŸ¤– Iniciando LotoScope AI Assistant...
python lotoscope_ai_chat.py
pause
"""
        
        with open(self.project_root / "Iniciar_LotoScope_AI.bat", 'w') as f:
            f.write(quick_start_script)
        
        print("âœ… Atalho criado: Iniciar_LotoScope_AI.bat")
    
    def show_completion_info(self, model_name):
        """Mostra informaÃ§Ãµes de conclusÃ£o"""
        print("\nğŸ‰" + "="*50 + "ğŸ‰")
        print("    INSTALAÃ‡ÃƒO CONCLUÃDA COM SUCESSO!")
        print("ğŸ‰" + "="*50 + "ğŸ‰")
        print()
        print("âœ… Ollama instalado e funcionando")
        print(f"âœ… Modelo {model_name} disponÃ­vel")
        print("âœ… Assistente IA configurado")
        print("âœ… Atalhos criados")
        print()
        print("ğŸš€ COMO USAR:")
        print("1. Execute: Iniciar_LotoScope_AI.bat")
        print("2. Ou: python lotoscope_ai_chat.py")
        print("3. Digite suas perguntas sobre loterias!")
        print()
        print("ğŸ’¡ COMANDOS ÃšTEIS:")
        print("   /analyze arquivo.py  - Analisa cÃ³digo")
        print("   /improve tÃ³pico      - Sugere melhorias")
        print("   /patterns megasena   - Pesquisa padrÃµes")
        print("   /help               - Ajuda completa")
        print()
        print("ğŸ¯ SEU ASSISTENTE IA ESTÃ PRONTO!")
    
    def run_installation(self):
        """Executa instalaÃ§Ã£o completa"""
        self.print_header()
        
        # Verificar requisitos
        if not self.check_system_requirements():
            return False
        
        # Verificar se jÃ¡ estÃ¡ instalado
        self.check_ollama_installed()
        
        # Baixar Ollama se necessÃ¡rio
        if not self.ollama_installed:
            if not self.download_ollama():
                return False
            
            if not self.install_ollama():
                return False
        
        # Listar modelos
        self.list_available_models()
        
        # Escolher modelo
        print("ğŸ¯ ESCOLHA UM MODELO:")
        print("1. llama3:8b (recomendado para comeÃ§ar)")
        print("2. llama3:70b (mais preciso, precisa mais RAM)")
        print("3. codellama:13b (especializado em cÃ³digo)")
        
        choice = input("\nğŸ‘¤ Sua escolha (1-3): ").strip()
        
        model_map = {"1": "llama3:8b", "2": "llama3:70b", "3": "codellama:13b"}
        model_name = model_map.get(choice, "llama3:8b")
        
        print(f"ğŸ¯ Modelo selecionado: {model_name}")
        
        # Instalar modelo
        if not self.install_model(model_name):
            print("âŒ Falha na instalaÃ§Ã£o do modelo")
            return False
        
        # Testar instalaÃ§Ã£o
        if not self.test_installation(model_name):
            print("âš ï¸ InstalaÃ§Ã£o pode ter problemas")
        
        # Instalar dependÃªncias Python
        self.install_python_dependencies()
        
        # Criar atalhos
        self.create_shortcuts()
        
        # Mostrar informaÃ§Ãµes finais
        self.show_completion_info(model_name)
        
        return True

def main():
    """FunÃ§Ã£o principal"""
    installer = LlamaSetupInstaller()
    
    try:
        success = installer.run_installation()
        
        if success:
            print("\nğŸ† SETUP CONCLUÃDO COM SUCESSO!")
            
            # Perguntar se quer iniciar agora
            start_now = input("\nğŸš€ Iniciar o assistente agora? (s/n): ").lower().strip()
            if start_now in ['s', 'sim', 'y', 'yes']:
                print("ğŸ¤– Iniciando LotoScope AI Assistant...")
                subprocess.run([sys.executable, 'lotoscope_ai_chat.py'])
        else:
            print("\nâŒ SETUP FALHOU!")
            print("ğŸ’¡ Tente a instalaÃ§Ã£o manual seguindo o guia")
    
    except KeyboardInterrupt:
        print("\nğŸ‘‹ InstalaÃ§Ã£o cancelada pelo usuÃ¡rio")
    except Exception as e:
        print(f"\nâŒ Erro inesperado: {e}")

if __name__ == "__main__":
    main()
