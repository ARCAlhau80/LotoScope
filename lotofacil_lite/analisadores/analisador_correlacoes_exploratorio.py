#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üîó ANALISADOR DE CORRELA√á√ïES EXPLORAT√ìRIO
=========================================
An√°lise profunda de correla√ß√µes entre n√∫meros, posi√ß√µes e sequ√™ncias hist√≥ricas
Busca por padr√µes n√£o-√≥bvios e interdepend√™ncias ocultas
"""

import pyodbc
import pandas as pd
import numpy as np
from scipy.stats import pearsonr, spearmanr, chi2_contingency
from scipy.cluster.hierarchy import linkage, dendrogram, fcluster
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict, Counter
from itertools import combinations, permutations
from datetime import datetime
import json
import networkx as nx

# Importa configura√ß√£o de banco existente
try:
    from database_optimizer import get_optimized_connection
    USE_OPTIMIZER = True
except ImportError:
    USE_OPTIMIZER = None

class AnalisadorCorrelacoes:
    """üîó Analisador avan√ßado de correla√ß√µes"""
    
    def __init__(self):
        self.conexao = None
        self.dados = None
        self.correlacoes_encontradas = []
        self.redes_descobertas = []
        
    def conectar_banco(self) -> bool:
        """üîå Conecta ao banco"""
        try:
            if USE_OPTIMIZER:
                self.conexao = get_optimized_connection()
                print("‚úÖ Analisador de correla√ß√µes conectado via optimizer")
                return True
        except Exception as e:
            print(f"‚ö†Ô∏è Optimizer falhou: {e}")
        
        # Fallback para conex√£o direta
        try:
            connection_string = (
                "DRIVER={ODBC Driver 17 for SQL Server};"
                "SERVER=DESKTOP-K6JPBDS\\SQLEXPRESS;"
                "DATABASE=LotofacilDB;"
                "Trusted_Connection=yes;"
                "MARS_Connection=Yes;"
            )
            self.conexao = pyodbc.connect(connection_string)
            print("‚úÖ Analisador de correla√ß√µes conectado diretamente")
            return True
        except Exception as e:
            print(f"‚ùå Erro na conex√£o: {e}")
            
            # Teste com dados sint√©ticos se n√£o conseguir conectar
            print("üîÑ Gerando dados sint√©ticos para demonstra√ß√£o...")
            return self._gerar_dados_sinteticos()
    
    def _gerar_dados_sinteticos(self) -> bool:
        """üé≤ Gera dados sint√©ticos para demonstra√ß√£o"""
        try:
            import random
            
            # Simula 500 concursos
            dados_sinteticos = []
            for concurso in range(1, 501):
                # Gera 15 n√∫meros aleat√≥rios √∫nicos entre 1 e 25
                numeros = sorted(random.sample(range(1, 26), 15))
                
                row = {'Concurso': concurso}
                for i, num in enumerate(numeros):
                    row[f'N{i+1}'] = num
                
                dados_sinteticos.append(row)
            
            self.dados = pd.DataFrame(dados_sinteticos)
            print(f"‚úÖ Dados sint√©ticos gerados: {len(self.dados)} concursos")
            
            # Cria matriz de presen√ßa sint√©tica
            self.matriz_presenca = np.zeros((len(self.dados), 25))
            numeros_cols = ['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8', 
                           'N9', 'N10', 'N11', 'N12', 'N13', 'N14', 'N15']
            
            for idx, row in self.dados.iterrows():
                for col in numeros_cols:
                    if pd.notna(row[col]):
                        numero = int(row[col]) - 1
                        if 0 <= numero < 25:
                            self.matriz_presenca[idx][numero] = 1
            
            print("‚ö†Ô∏è ATEN√á√ÉO: Usando dados SINT√âTICOS para demonstra√ß√£o")
            return True
            
        except Exception as e:
            print(f"‚ùå Erro ao gerar dados sint√©ticos: {e}")
            return False
    
    def carregar_dados_completos(self) -> bool:
        """üìä Carrega dados completos para an√°lise"""
        # Se j√° temos matriz de presen√ßa (dados sint√©ticos), pula
        if hasattr(self, 'matriz_presenca') and self.matriz_presenca is not None:
            return True
            
        if not self.conexao:
            return False
        
        try:
            # Carrega todos os dados hist√≥ricos
            query = """
            SELECT Concurso, N1, N2, N3, N4, N5, N6, N7, N8, N9, N10,
                   N11, N12, N13, N14, N15
            FROM resultados_int 
            WHERE Concurso IS NOT NULL 
                AND N1 IS NOT NULL 
                AND N15 IS NOT NULL
            ORDER BY Concurso
            """
            
            self.dados = pd.read_sql(query, self.conexao)
            print(f"üìä Carregados {len(self.dados)} concursos completos")
            
            # Cria matriz de presen√ßa (0/1) para cada n√∫mero
            self.matriz_presenca = np.zeros((len(self.dados), 25))  # 25 n√∫meros poss√≠veis
            
            numeros_cols = ['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8', 
                           'N9', 'N10', 'N11', 'N12', 'N13', 'N14', 'N15']
            
            for idx, row in self.dados.iterrows():
                for col in numeros_cols:
                    if pd.notna(row[col]):
                        numero = int(row[col]) - 1  # Ajusta para √≠ndice 0-based
                        if 0 <= numero < 25:
                            self.matriz_presenca[idx][numero] = 1
            
            print(f"‚úÖ Matriz de presen√ßa criada: {self.matriz_presenca.shape}")
            return True
            
        except Exception as e:
            print(f"‚ùå Erro ao carregar dados: {e}")
            return False
    
    def analisar_correlacoes_par_a_par(self):
        """üîó An√°lise de correla√ß√µes entre pares de n√∫meros"""
        print("\nüîó AN√ÅLISE DE CORRELA√á√ïES PAR-A-PAR")
        print("=" * 45)
        
        # Calcula correla√ß√µes entre todos os pares de n√∫meros
        correlacoes_fortes = []
        
        for i in range(25):
            for j in range(i + 1, 25):
                # Correla√ß√£o de Pearson (linear)
                corr_pearson, p_pearson = pearsonr(self.matriz_presenca[:, i], 
                                                 self.matriz_presenca[:, j])
                
                # Correla√ß√£o de Spearman (monot√¥nica)
                corr_spearman, p_spearman = spearmanr(self.matriz_presenca[:, i], 
                                                    self.matriz_presenca[:, j])
                
                # Considera significativo se p < 0.05 e |corr| > 0.1
                if (p_pearson < 0.05 and abs(corr_pearson) > 0.1) or \
                   (p_spearman < 0.05 and abs(corr_spearman) > 0.1):
                    
                    correlacoes_fortes.append({
                        'numero1': i + 1,
                        'numero2': j + 1,
                        'pearson': corr_pearson,
                        'p_pearson': p_pearson,
                        'spearman': corr_spearman,
                        'p_spearman': p_spearman,
                        'tipo': 'positiva' if max(corr_pearson, corr_spearman) > 0 else 'negativa'
                    })
        
        # Ordena por for√ßa da correla√ß√£o
        correlacoes_fortes.sort(key=lambda x: max(abs(x['pearson']), abs(x['spearman'])), reverse=True)
        
        print(f"‚úÖ Encontradas {len(correlacoes_fortes)} correla√ß√µes significativas:")
        
        for i, corr in enumerate(correlacoes_fortes[:10]):  # Top 10
            print(f"   {i+1:2d}. N√∫meros {corr['numero1']:2d} ‚Üî {corr['numero2']:2d}: "
                  f"r={corr['pearson']:+.3f} (p={corr['p_pearson']:.3f}) | "
                  f"œÅ={corr['spearman']:+.3f} ({corr['tipo']})")
        
        if len(correlacoes_fortes) > 10:
            print(f"   ... e mais {len(correlacoes_fortes) - 10} correla√ß√µes")
        
        self.correlacoes_encontradas.extend(correlacoes_fortes)
        return correlacoes_fortes
    
    def analisar_clusters_de_numeros(self):
        """üìä An√°lise de clusters usando hierarchical clustering"""
        print("\nüìä AN√ÅLISE DE CLUSTERS DE N√öMEROS")
        print("=" * 37)
        
        # Calcula matriz de correla√ß√£o completa
        matriz_corr = np.corrcoef(self.matriz_presenca.T)
        
        # Converte correla√ß√£o em dist√¢ncia (1 - |corr|)
        matriz_distancia = 1 - np.abs(matriz_corr)
        
        # Clustering hier√°rquico
        linkage_matrix = linkage(matriz_distancia, method='ward')
        
        # Forma clusters
        n_clusters = 5  # Tenta 5 clusters
        clusters = fcluster(linkage_matrix, n_clusters, criterion='maxclust')
        
        # Organiza n√∫meros por cluster
        clusters_organizados = defaultdict(list)
        for numero, cluster in enumerate(clusters):
            clusters_organizados[cluster].append(numero + 1)
        
        print(f"‚úÖ {len(clusters_organizados)} clusters identificados:")
        
        for cluster_id, numeros in clusters_organizados.items():
            # Calcula estat√≠sticas do cluster
            frequencia_media = np.mean([np.sum(self.matriz_presenca[:, n-1]) for n in numeros])
            
            print(f"   üéØ Cluster {cluster_id}: {numeros}")
            print(f"      Frequ√™ncia m√©dia: {frequencia_media:.1f} apari√ß√µes")
            
            # Analisa co-ocorr√™ncia dentro do cluster
            if len(numeros) > 1:
                co_ocorrencias = []
                for i, num1 in enumerate(numeros):
                    for num2 in numeros[i+1:]:
                        # Conta quantas vezes aparecem juntos
                        juntos = np.sum(self.matriz_presenca[:, num1-1] * self.matriz_presenca[:, num2-1])
                        total_jogos = len(self.dados)
                        co_ocorrencias.append((num1, num2, juntos, juntos/total_jogos))
                
                # Mostra as co-ocorr√™ncias mais altas
                co_ocorrencias.sort(key=lambda x: x[3], reverse=True)
                if co_ocorrencias:
                    print(f"      Co-ocorr√™ncia forte: {co_ocorrencias[0][0]} & {co_ocorrencias[0][1]} "
                          f"({co_ocorrencias[0][2]} vezes, {co_ocorrencias[0][3]:.1%})")
        
        self.redes_descobertas.append({
            'tipo': 'clusters_hierarquicos',
            'clusters': dict(clusters_organizados),
            'linkage_matrix': linkage_matrix.tolist()  # Para JSON
        })
        
        return clusters_organizados
    
    def analisar_sequencias_temporais(self):
        """‚è∞ An√°lise de padr√µes em sequ√™ncias temporais"""
        print("\n‚è∞ AN√ÅLISE DE SEQU√äNCIAS TEMPORAIS")
        print("=" * 38)
        
        # Analisa tend√™ncias por janelas deslizantes
        tamanhos_janela = [5, 10, 20, 50]
        padroes_temporais = []
        
        for janela in tamanhos_janela:
            print(f"\nüìä Analisando janela de {janela} concursos:")
            
            # Para cada n√∫mero, verifica tend√™ncias
            tendencias_significativas = []
            
            for numero in range(1, 26):
                serie_temporal = self.matriz_presenca[:, numero-1]
                
                # Calcula m√©dias m√≥veis
                if len(serie_temporal) >= janela * 2:
                    medias_moveis = []
                    for i in range(janela, len(serie_temporal) - janela):
                        janela_antes = np.mean(serie_temporal[i-janela:i])
                        janela_depois = np.mean(serie_temporal[i:i+janela])
                        medias_moveis.append(janela_depois - janela_antes)
                    
                    # Verifica se h√° tend√™ncia consistente
                    if medias_moveis:
                        tendencia_media = np.mean(medias_moveis)
                        variabilidade = np.std(medias_moveis)
                        
                        # Considera significativo se tend√™ncia > 2 * variabilidade
                        if abs(tendencia_media) > 2 * variabilidade and variabilidade > 0:
                            tendencias_significativas.append({
                                'numero': numero,
                                'tendencia': tendencia_media,
                                'confianca': abs(tendencia_media) / variabilidade,
                                'direcao': 'crescente' if tendencia_media > 0 else 'decrescente'
                            })
            
            # Ordena por confian√ßa
            tendencias_significativas.sort(key=lambda x: x['confianca'], reverse=True)
            
            if tendencias_significativas:
                print(f"   ‚úÖ {len(tendencias_significativas)} tend√™ncias detectadas:")
                for tend in tendencias_significativas[:5]:  # Top 5
                    print(f"      ‚Ä¢ N√∫mero {tend['numero']:2d}: {tend['direcao']} "
                          f"(for√ßa: {tend['confianca']:.1f})")
                
                padroes_temporais.append({
                    'janela': janela,
                    'tendencias': tendencias_significativas
                })
            else:
                print("   ‚ö™ Nenhuma tend√™ncia significativa")
        
        return padroes_temporais
    
    def analisar_redes_de_influencia(self):
        """üï∏Ô∏è An√°lise de redes de influ√™ncia entre n√∫meros"""
        print("\nüï∏Ô∏è AN√ÅLISE DE REDES DE INFLU√äNCIA")
        print("=" * 37)
        
        # Cria grafo de influ√™ncias baseado em correla√ß√µes
        G = nx.Graph()
        
        # Adiciona n√≥s (n√∫meros)
        for i in range(1, 26):
            freq = np.sum(self.matriz_presenca[:, i-1])
            G.add_node(i, frequencia=freq)
        
        # Adiciona arestas baseadas em correla√ß√µes significativas
        for corr in self.correlacoes_encontradas:
            if max(abs(corr['pearson']), abs(corr['spearman'])) > 0.15:  # Limiar mais alto
                peso = max(abs(corr['pearson']), abs(corr['spearman']))
                G.add_edge(corr['numero1'], corr['numero2'], peso=peso)
        
        # Calcula m√©tricas de centralidade
        degree_centrality = nx.degree_centrality(G)
        betweenness_centrality = nx.betweenness_centrality(G)
        closeness_centrality = nx.closeness_centrality(G)
        
        # Identifica n√∫meros mais "influentes"
        numeros_influentes = []
        for numero in range(1, 26):
            if numero in G.nodes():
                influencia = (degree_centrality.get(numero, 0) + 
                            betweenness_centrality.get(numero, 0) + 
                            closeness_centrality.get(numero, 0)) / 3
                numeros_influentes.append((numero, influencia))
        
        numeros_influentes.sort(key=lambda x: x[1], reverse=True)
        
        print(f"‚úÖ Rede de {G.number_of_nodes()} n√≥s e {G.number_of_edges()} conex√µes:")
        print("   üéØ N√∫meros mais influentes:")
        for i, (numero, influencia) in enumerate(numeros_influentes[:8]):
            grau = G.degree(numero) if numero in G.nodes() else 0
            print(f"      {i+1}. N√∫mero {numero:2d}: influ√™ncia {influencia:.3f} "
                  f"({grau} conex√µes)")
        
        # Detecta comunidades
        try:
            import networkx.algorithms.community as nx_comm
            comunidades = nx_comm.greedy_modularity_communities(G)
            
            print(f"\n   üèòÔ∏è {len(comunidades)} comunidades detectadas:")
            for i, comunidade in enumerate(comunidades):
                nums = sorted(list(comunidade))
                if len(nums) > 1:
                    print(f"      Comunidade {i+1}: {nums}")
            
            self.redes_descobertas.append({
                'tipo': 'rede_influencia',
                'nos': len(G.nodes()),
                'arestas': len(G.edges()),
                'comunidades': [list(c) for c in comunidades],
                'centralidade': dict(numeros_influentes)
            })
        except ImportError:
            print("   ‚ö†Ô∏è Detec√ß√£o de comunidades n√£o dispon√≠vel")
        
        return numeros_influentes, G
    
    def analisar_padroes_posicionais(self):
        """üìç An√°lise de padr√µes posicionais"""
        print("\nüìç AN√ÅLISE DE PADR√ïES POSICIONAIS")
        print("=" * 38)
        
        numeros_cols = ['N1', 'N2', 'N3', 'N4', 'N5', 'N6', 'N7', 'N8', 
                       'N9', 'N10', 'N11', 'N12', 'N13', 'N14', 'N15']
        
        padroes_posicionais = {}
        
        # Analisa cada posi√ß√£o
        for pos, col in enumerate(numeros_cols, 1):
            numeros_nesta_posicao = self.dados[col].dropna().astype(int)
            
            # Estat√≠sticas da posi√ß√£o
            media = numeros_nesta_posicao.mean()
            desvio = numeros_nesta_posicao.std()
            moda = numeros_nesta_posicao.mode().iloc[0] if len(numeros_nesta_posicao.mode()) > 0 else None
            
            # N√∫meros que aparecem frequentemente nesta posi√ß√£o
            freq_posicao = Counter(numeros_nesta_posicao)
            total_aparicoes = len(numeros_nesta_posicao)
            
            # Identifica n√∫meros "especiais" para esta posi√ß√£o
            numeros_frequentes = []
            for numero, freq in freq_posicao.most_common(5):
                prob_esperada = 1/25  # 4% se fosse aleat√≥rio
                prob_observada = freq / total_aparicoes
                if prob_observada > prob_esperada * 1.5:  # 50% acima do esperado
                    numeros_frequentes.append({
                        'numero': numero,
                        'frequencia': freq,
                        'probabilidade': prob_observada,
                        'excesso': prob_observada / prob_esperada
                    })
            
            if numeros_frequentes:
                padroes_posicionais[pos] = {
                    'media': media,
                    'desvio': desvio,
                    'moda': moda,
                    'numeros_frequentes': numeros_frequentes
                }
        
        # Exibe resultados
        print("‚úÖ Padr√µes posicionais detectados:")
        for pos, dados in padroes_posicionais.items():
            print(f"\n   üìç Posi√ß√£o {pos:2d} (m√©dia: {dados['media']:.1f}):")
            for nf in dados['numeros_frequentes'][:3]:  # Top 3
                print(f"      ‚Ä¢ N√∫mero {nf['numero']:2d}: {nf['probabilidade']:.1%} "
                      f"({nf['excesso']:.1f}x esperado)")
        
        return padroes_posicionais
    
    def gerar_relatorio_correlacoes(self):
        """üìã Gera relat√≥rio final de correla√ß√µes"""
        print("\n" + "="*60)
        print("üìã RELAT√ìRIO DE CORRELA√á√ïES EXPLORAT√ìRIAS")
        print("="*60)
        
        # Resumo das descobertas
        total_correlacoes = len(self.correlacoes_encontradas)
        total_redes = len(self.redes_descobertas)
        
        print(f"\nüìä RESUMO DAS DESCOBERTAS:")
        print(f"   ‚Ä¢ {total_correlacoes} correla√ß√µes significativas detectadas")
        print(f"   ‚Ä¢ {total_redes} estruturas de rede identificadas")
        
        # Salva resultados
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        resultado = {
            'timestamp': timestamp,
            'correlacoes_par_a_par': [
                {k: (float(v) if isinstance(v, np.floating) else v) for k, v in corr.items()}
                for corr in self.correlacoes_encontradas
            ],
            'redes_descobertas': [
                {k: (v if k != 'clusters' else {str(ck): cv for ck, cv in v.items()}) 
                 for k, v in rede.items()}
                for rede in self.redes_descobertas
            ],
            'estatisticas': {
                'total_concursos_analisados': int(len(self.dados)),
                'total_correlacoes': int(total_correlacoes),
                'total_redes': int(total_redes)
            }
        }
        
        nome_arquivo = f"correlacoes_exploratoria_{timestamp}.json"
        with open(nome_arquivo, 'w', encoding='utf-8') as f:
            json.dump(resultado, f, indent=2, ensure_ascii=False)
        
        print(f"\nüíæ Resultados salvos em: {nome_arquivo}")
        
        # Recomenda√ß√£o final
        if total_correlacoes > 20:
            print("\nüéØ RECOMENDA√á√ÉO: Correla√ß√µes abundantes - Implementar sistema!")
            return True
        elif total_correlacoes > 10:
            print("\nüìà RECOMENDA√á√ÉO: Correla√ß√µes moderadas - Explorar mais")
            return True
        else:
            print("\n‚ö™ RECOMENDA√á√ÉO: Correla√ß√µes limitadas - Continuar pesquisa")
            return False
    
    def executar_analise_completa(self):
        """üöÄ Executa an√°lise completa de correla√ß√µes"""
        print("üîó ANALISADOR DE CORRELA√á√ïES EXPLORAT√ìRIO")
        print("="*45)
        
        if not self.conectar_banco() or not self.carregar_dados_completos():
            return False
        
        # Executa todas as an√°lises
        self.analisar_correlacoes_par_a_par()
        self.analisar_clusters_de_numeros()
        self.analisar_sequencias_temporais()
        self.analisar_redes_de_influencia()
        self.analisar_padroes_posicionais()
        
        # Gera relat√≥rio final
        return self.gerar_relatorio_correlacoes()

def main():
    """Fun√ß√£o principal"""
    analisador = AnalisadorCorrelacoes()
    return analisador.executar_analise_completa()

if __name__ == "__main__":
    main()