#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
üß† SISTEMA NEURAL NETWORK V7.0 - LOTOF√ÅCIL
==========================================
‚úÖ Dados 100% REAIS (Resultados_INT + NumerosCiclos)
‚úÖ Rede Neural Deep Learning com PADR√ïES ALTOS/BAIXOS
‚úÖ Meta: 76%+ (11/15 acertos) - Melhorada com an√°lise de distribui√ß√£o
‚úÖ An√°lise de padr√µes ultra-complexos + Tend√™ncias de Revers√£o
"""

import numpy as np
import pandas as pd
from datetime import datetime
import sys
import os
from pathlib import Path

# Configurar paths para imports
_BASE_DIR = Path(__file__).parent.parent
sys.path.insert(0, str(_BASE_DIR))
sys.path.insert(0, str(_BASE_DIR / 'utils'))

from database_config import db_config

# üöÄ SISTEMA DE OTIMIZA√á√ÉO DE BANCO
try:
    from database_optimizer import DatabaseOptimizer
    _db_optimizer = DatabaseOptimizer()
except ImportError:
    _db_optimizer = None

from collections import Counter, defaultdict
from sklearn.neural_network import MLPRegressor, MLPClassifier
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.multioutput import MultiOutputClassifier
from sklearn.metrics import accuracy_score, classification_report
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import warnings
warnings.filterwarnings('ignore')

class SistemaNeuralNetworkV7:
    def __init__(self):
        self.meta_acertos = 11  # 76% = 11/15 acertos
        self.resultado_teste = [3,5,6,8,9,12,13,14,15,16,17,20,21,22,23]
        
        # Dados carregados
        self.dados_historicos = []
        self.dados_ciclos = []
        self.features_completas = []
        
        # Modelos treinados
        self.modelo_neural_tf = None
        self.modelo_ensemble = {}
        self.scalers = {}
        
        # üÜï PADR√ïES ALTOS/BAIXOS
        self.padroes_distribuicao = {}
        self.historico_tendencias = []
        
        # Database config
        self.db_config = db_config
        
        print("üß† Sistema Neural Network V7.0 Inicializado")
        print("üéØ Meta: 76%+ (11/15 acertos)")
        print("üÜï NOVA FEATURE: An√°lise de distribui√ß√£o Altos/Baixos")
    
    def carregar_dados_reais(self):
        """Carrega dados reais das tabelas Resultados_INT e NumerosCiclos"""
        print("\nüîç Carregando dados hist√≥ricos reais...")
        
        try:
            if not self.db_config.test_connection():
                print("‚ùå Erro na conex√£o com banco")
                return False
            
            # Carregar resultados hist√≥ricos
            query_resultados = """
            SELECT TOP 500 Concurso, N1, N2, N3, N4, N5, N6, N7, N8, N9, N10, N11, N12, N13, N14, N15
            FROM Resultados_INT
            ORDER BY Concurso DESC
            """
            
            resultados = self.db_config.execute_query(query_resultados)
            
            for row in resultados:
                concurso = row[0]
                numeros = [row[i] for i in range(1, 16)]
                
                # üÜï AN√ÅLISE ALTOS/BAIXOS (excluindo N1)
                numeros_sem_n1 = numeros[1:]  # N2 at√© N15
                baixos = [n for n in numeros_sem_n1 if 2 <= n <= 13]
                altos = [n for n in numeros_sem_n1 if 14 <= n <= 25]
                
                # Categorizar distribui√ß√£o
                distribuicao = self.categorizar_distribuicao(len(baixos), len(altos))
                
                self.dados_historicos.append({
                    'concurso': concurso,
                    'numeros': sorted(numeros),
                    'qtd_baixos': len(baixos),
                    'qtd_altos': len(altos),
                    'distribuicao': distribuicao,
                    'proporcao_baixos': len(baixos) / 14,
                    'proporcao_altos': len(altos) / 14,
                    'amplitude': max(numeros) - min(numeros),
                    'densidade': self.calcular_densidade(numeros)
                })
            
            # Carregar dados de ciclos
            query_ciclos = """
            SELECT TOP 500 Numero, Ciclo, QtdSorteados, ConcursoInicio
            FROM NumerosCiclos
            ORDER BY Numero, Ciclo DESC
            """
            
            ciclos = self.db_config.execute_query(query_ciclos)
            
            for row in ciclos:
                self.dados_ciclos.append({
                    'numero': row[0],
                    'ciclo': row[1],
                    'qtd_sorteados': row[2],
                    'concurso_inicio': row[3]
                })
            
            # üÜï CALCULAR TEND√äNCIAS DE TRANSI√á√ÉO
            self.calcular_tendencias_historicas()
            
            print(f"‚úÖ {len(self.dados_historicos)} concursos carregados")
            print(f"‚úÖ {len(self.dados_ciclos)} registros de ciclos carregados")
            print(f"‚úÖ An√°lise de tend√™ncias Altos/Baixos calculada")
            
            return True
            
        except Exception as e:
            print(f"‚ùå Erro ao carregar dados: {e}")
            return False
    
    def categorizar_distribuicao(self, qtd_baixos, qtd_altos):
        """Categoriza a distribui√ß√£o entre altos e baixos"""
        if qtd_baixos > qtd_altos + 2:
            return 'muito_mais_baixos'
        elif qtd_baixos > qtd_altos + 1:
            return 'mais_baixos'
        elif qtd_altos > qtd_baixos + 2:
            return 'muito_mais_altos'
        elif qtd_altos > qtd_baixos + 1:
            return 'mais_altos'
        elif qtd_baixos == qtd_altos + 1:
            return 'ligeiro_baixos'
        elif qtd_altos == qtd_baixos + 1:
            return 'ligeiro_altos'
        else:
            return 'equilibrio'
    
    def calcular_densidade(self, numeros):
        """Calcula densidade num√©rica dos n√∫meros sorteados"""
        if len(numeros) <= 1:
            return 0
        return len(numeros) / (max(numeros) - min(numeros))
    
    def calcular_tendencias_historicas(self):
        """üÜï Calcula tend√™ncias de transi√ß√£o baseado na an√°lise realizada"""
        print("üîÑ Calculando tend√™ncias de transi√ß√£o...")
        
        # Probabilidades descobertas na an√°lise
        self.padroes_distribuicao = {
            'mais_baixos': {
                'para_mais_altos': 0.428,
                'para_equilibrio': 0.304,
                'para_mais_baixos': 0.268
            },
            'equilibrio': {
                'para_mais_altos': 0.387,
                'para_mais_baixos': 0.311,
                'para_equilibrio': 0.302
            },
            'mais_altos': {
                'para_mais_altos': 0.408,
                'para_equilibrio': 0.303,
                'para_mais_baixos': 0.289
            }
        }
        
        # Calcular tend√™ncias para √∫ltimos jogos
        for i in range(len(self.dados_historicos) - 1):
            atual = self.dados_historicos[i]
            proximo = self.dados_historicos[i + 1]
            
            # Simplificar categorias para usar as probabilidades
            cat_atual = self.simplificar_categoria(atual['distribuicao'])
            cat_proximo = self.simplificar_categoria(proximo['distribuicao'])
            
            self.historico_tendencias.append({
                'concurso': atual['concurso'],
                'categoria_atual': cat_atual,
                'categoria_proxima': cat_proximo,
                'probabilidade_teorica': self.padroes_distribuicao.get(cat_atual, {}).get(f'para_{cat_proximo}', 0.33)
            })
    
    def simplificar_categoria(self, categoria):
        """Simplifica categorias para usar as probabilidades calculadas"""
        if 'baixos' in categoria:
            return 'mais_baixos'
        elif 'altos' in categoria:
            return 'mais_altos'
        else:
            return 'equilibrio'
    
    def extrair_features_avancadas(self):
        """Extrai features avan√ßadas incluindo padr√µes de distribui√ß√£o"""
        print("üß¨ Extraindo features avan√ßadas...")
        
        self.features_completas = []
        
        for i, dados in enumerate(self.dados_historicos):
            if i < 10:  # Precisamos de hist√≥rico para calcular features
                continue
            
            # Features b√°sicas
            features = {
                'concurso': dados['concurso'],
                'amplitude': dados['amplitude'],
                'densidade': dados['densidade'],
                'qtd_baixos': dados['qtd_baixos'],
                'qtd_altos': dados['qtd_altos'],
                'proporcao_baixos': dados['proporcao_baixos'],
                'proporcao_altos': dados['proporcao_altos']
            }
            
            # üÜï FEATURES DE DISTRIBUI√á√ÉO
            distribuicao_encoded = self.encode_distribuicao(dados['distribuicao'])
            features.update(distribuicao_encoded)
            
            # üÜï FEATURES DE TEND√äNCIA (√∫ltimos 3 jogos)
            if i >= 3:
                ultimos_3 = self.dados_historicos[i-3:i]
                features.update(self.extrair_features_tendencia(ultimos_3))
            
            # üÜï PROBABILIDADE DE REVERS√ÉO
            if i >= 1:
                jogo_anterior = self.dados_historicos[i-1]
                cat_anterior = self.simplificar_categoria(jogo_anterior['distribuicao'])
                features['prob_reversao_alto'] = self.padroes_distribuicao.get(cat_anterior, {}).get('para_mais_altos', 0.33)
                features['prob_reversao_baixo'] = self.padroes_distribuicao.get(cat_anterior, {}).get('para_mais_baixos', 0.33)
                features['prob_equilibrio'] = self.padroes_distribuicao.get(cat_anterior, {}).get('para_equilibrio', 0.33)
            
            # Features de n√∫meros espec√≠ficos
            numeros_binary = np.zeros(25)
            for num in dados['numeros']:
                if 1 <= num <= 25:
                    numeros_binary[num-1] = 1
            
            for j in range(25):
                features[f'numero_{j+1}'] = numeros_binary[j]
            
            # Features de ciclos
            features_ciclos = self.extrair_features_ciclos(dados['concurso'])
            features.update(features_ciclos)
            
            # Features de padr√µes hist√≥ricos
            features_historicos = self.extrair_features_historicos(i)
            features.update(features_historicos)
            
            self.features_completas.append(features)
        
        print(f"‚úÖ {len(self.features_completas)} conjuntos de features extra√≠das")
        print(f"‚úÖ Total de features por jogo: {len(self.features_completas[0])}")
    
    def encode_distribuicao(self, distribuicao):
        """Codifica distribui√ß√£o em features bin√°rias"""
        categorias = ['muito_mais_baixos', 'mais_baixos', 'ligeiro_baixos', 
                     'equilibrio', 'ligeiro_altos', 'mais_altos', 'muito_mais_altos']
        
        encoded = {}
        for cat in categorias:
            encoded[f'dist_{cat}'] = 1 if distribuicao == cat else 0
        
        return encoded
    
    def extrair_features_tendencia(self, ultimos_jogos):
        """üÜï Extrai features de tend√™ncia dos √∫ltimos jogos"""
        features = {}
        
        # Contagem de padr√µes nos √∫ltimos jogos
        distribuicoes = [jogo['distribuicao'] for jogo in ultimos_jogos]
        
        features['tend_baixos_seq'] = sum(1 for d in distribuicoes if 'baixos' in d)
        features['tend_altos_seq'] = sum(1 for d in distribuicoes if 'altos' in d)
        features['tend_equilibrio_seq'] = sum(1 for d in distribuicoes if d == 'equilibrio')
        
        # Momentum de mudan√ßa
        if len(ultimos_jogos) >= 2:
            features['momentum_mudanca'] = 1 if ultimos_jogos[-1]['distribuicao'] != ultimos_jogos[-2]['distribuicao'] else 0
        
        # For√ßa da tend√™ncia atual
        ultima_categoria = self.simplificar_categoria(ultimos_jogos[-1]['distribuicao'])
        features['forca_tendencia'] = sum(1 for jogo in ultimos_jogos 
                                        if self.simplificar_categoria(jogo['distribuicao']) == ultima_categoria)
        
        return features
    
    def extrair_features_ciclos(self, concurso):
        """Extrai features baseadas nos ciclos dos n√∫meros"""
        features = {}
        
        # Para cada n√∫mero, buscar informa√ß√µes de ciclo
        ciclos_por_numero = defaultdict(list)
        for ciclo in self.dados_ciclos:
            ciclos_por_numero[ciclo['numero']].append(ciclo)
        
        # Estat√≠sticas de ciclos
        features['ciclo_medio'] = 0
        features['qtd_sorteados_medio'] = 0
        features['numeros_ciclo_alto'] = 0
        
        contador = 0
        for num in range(1, 26):
            if num in ciclos_por_numero:
                ciclo_info = ciclos_por_numero[num][0]  # Mais recente
                features['ciclo_medio'] += ciclo_info['ciclo']
                features['qtd_sorteados_medio'] += ciclo_info['qtd_sorteados']
                
                # N√∫meros com muitos sorteios no ciclo (alta atividade)
                if ciclo_info['qtd_sorteados'] > 5:
                    features['numeros_ciclo_alto'] += 1
                
                contador += 1
        
        if contador > 0:
            features['ciclo_medio'] /= contador
            features['qtd_sorteados_medio'] /= contador
        
        return features
    
    def extrair_features_historicos(self, indice):
        """Extrai features baseadas em padr√µes hist√≥ricos"""
        features = {}
        
        if indice < 10:
            return features
        
        # An√°lise dos √∫ltimos 10 jogos
        ultimos_10 = self.dados_historicos[max(0, indice-10):indice]
        
        # Estat√≠sticas gerais
        features['media_baixos_10'] = np.mean([j['qtd_baixos'] for j in ultimos_10])
        features['media_altos_10'] = np.mean([j['qtd_altos'] for j in ultimos_10])
        features['std_baixos_10'] = np.std([j['qtd_baixos'] for j in ultimos_10])
        features['std_altos_10'] = np.std([j['qtd_altos'] for j in ultimos_10])
        
        # Frequ√™ncia de cada categoria
        distribuicoes_10 = [j['distribuicao'] for j in ultimos_10]
        contador_dist = Counter(distribuicoes_10)
        
        for categoria in ['muito_mais_baixos', 'mais_baixos', 'equilibrio', 'mais_altos', 'muito_mais_altos']:
            features[f'freq_{categoria}_10'] = contador_dist.get(categoria, 0) / len(ultimos_10)
        
        return features
    
    def treinar_modelos(self):
        """Treina os modelos de machine learning"""
        print("\nü§ñ Treinando modelos de Machine Learning...")
        
        if not self.features_completas:
            print("‚ùå Features n√£o extra√≠das")
            return False
        
        # Preparar dados
        X = []
        y = []
        
        for i, features in enumerate(self.features_completas[:-1]):  # Excluir √∫ltimo para ter target
            # Input features (excluindo n√∫meros espec√≠ficos e concurso)
            feature_vector = []
            for key, value in features.items():
                if not key.startswith('numero_') and key != 'concurso':
                    feature_vector.append(value)
            
            X.append(feature_vector)
            
            # Target: pr√≥ximo jogo (√≠ndice i+1)
            proximo_jogo = self.dados_historicos[i+1]
            target = np.zeros(25)
            for num in proximo_jogo['numeros']:
                if 1 <= num <= 25:
                    target[num-1] = 1
            
            y.append(target)
        
        X = np.array(X)
        y = np.array(y)
        
        print(f"üìä Shape dos dados: X={X.shape}, y={y.shape}")
        
        # Split treino/teste
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42
        )
        
        # Normaliza√ß√£o
        self.scalers['standard'] = StandardScaler()
        X_train_scaled = self.scalers['standard'].fit_transform(X_train)
        X_test_scaled = self.scalers['standard'].transform(X_test)
        
        # 1. Modelo TensorFlow/Keras - MELHORADO
        print("üß† Treinando Rede Neural TensorFlow...")
        
        self.modelo_neural_tf = keras.Sequential([
            # Camada de entrada com dropout
            layers.Dense(512, activation='relu', input_shape=(X_train_scaled.shape[1],)),
            layers.Dropout(0.3),
            layers.BatchNormalization(),
            
            # Camadas ocultas com arquitetura mais profunda
            layers.Dense(256, activation='relu'),
            layers.Dropout(0.3),
            layers.BatchNormalization(),
            
            layers.Dense(128, activation='relu'),
            layers.Dropout(0.2),
            layers.BatchNormalization(),
            
            layers.Dense(64, activation='relu'),
            layers.Dropout(0.2),
            
            # Camada de sa√≠da para 25 n√∫meros
            layers.Dense(25, activation='sigmoid')
        ])
        
        # Compilar com otimizador melhorado
        self.modelo_neural_tf.compile(
            optimizer=keras.optimizers.Adam(learning_rate=0.001),
            loss='binary_crossentropy',
            metrics=['accuracy']
        )
        
        # Treinamento com early stopping
        early_stopping = keras.callbacks.EarlyStopping(
            monitor='val_loss', patience=10, restore_best_weights=True
        )
        
        reduce_lr = keras.callbacks.ReduceLROnPlateau(
            monitor='val_loss', factor=0.5, patience=5, min_lr=0.00001
        )
        
        history = self.modelo_neural_tf.fit(
            X_train_scaled, y_train,
            validation_data=(X_test_scaled, y_test),
            epochs=100,
            batch_size=32,
            callbacks=[early_stopping, reduce_lr],
            verbose=0
        )
        
        # 2. Ensemble de modelos
        print("üéØ Treinando Ensemble de modelos...")
        
        self.modelo_ensemble = {
            'random_forest': MultiOutputClassifier(
                RandomForestClassifier(
                    n_estimators=300,  # Aumentado
                    max_depth=25,      # Aumentado
                    min_samples_split=3,
                    min_samples_leaf=1,
                    random_state=42,
                    n_jobs=-1
                )
            ),
            'gradient_boosting': MultiOutputClassifier(
                GradientBoostingClassifier(
                    n_estimators=200,
                    learning_rate=0.1,
                    max_depth=8,
                    random_state=42
                )
            )
        }
        
        for nome, modelo in self.modelo_ensemble.items():
            print(f"   Treinando {nome}...")
            modelo.fit(X_train_scaled, y_train)
        
        # Avaliar modelos
        print("\nüìä Avalia√ß√£o dos modelos:")
        
        # TensorFlow
        y_pred_tf = self.modelo_neural_tf.predict(X_test_scaled, verbose=0)
        y_pred_tf_binary = (y_pred_tf > 0.5).astype(int)
        acc_tf = accuracy_score(y_test.flatten(), y_pred_tf_binary.flatten())
        print(f"   üß† TensorFlow: {acc_tf:.3f}")
        
        # Ensemble
        for nome, modelo in self.modelo_ensemble.items():
            y_pred = modelo.predict(X_test_scaled)
            acc = accuracy_score(y_test.flatten(), y_pred.flatten())
            print(f"   üéØ {nome}: {acc:.3f}")
        
        print("‚úÖ Modelos treinados com sucesso!")
        return True
    
    def gerar_predicao_inteligente(self):
        """Gera predi√ß√£o inteligente usando ensemble e padr√µes de distribui√ß√£o"""
        print("\nüîÆ Gerando predi√ß√£o inteligente...")
        
        if not self.modelo_neural_tf or not self.modelo_ensemble:
            print("‚ùå Modelos n√£o treinados")
            return None
        
        # Usar o √∫ltimo jogo para predi√ß√£o
        ultimo_jogo = self.features_completas[-1]
        
        # Preparar features
        feature_vector = []
        for key, value in ultimo_jogo.items():
            if not key.startswith('numero_') and key != 'concurso':
                feature_vector.append(value)
        
        X_pred = np.array([feature_vector])
        X_pred_scaled = self.scalers['standard'].transform(X_pred)
        
        # Predi√ß√µes dos modelos
        pred_tf = self.modelo_neural_tf.predict(X_pred_scaled, verbose=0)[0]
        
        pred_ensemble = {}
        for nome, modelo in self.modelo_ensemble.items():
            pred_ensemble[nome] = modelo.predict(X_pred_scaled)[0]
        
        # üÜï APLICAR PADR√ïES DE DISTRIBUI√á√ÉO
        ultimo_historico = self.dados_historicos[-1]
        categoria_atual = self.simplificar_categoria(ultimo_historico['distribuicao'])
        
        print(f"üìä Situa√ß√£o atual: {ultimo_historico['distribuicao']}")
        print(f"üìä Categoria: {categoria_atual}")
        
        # Ajustar predi√ß√µes baseado em padr√µes de distribui√ß√£o
        prob_mais_altos = self.padroes_distribuicao.get(categoria_atual, {}).get('para_mais_altos', 0.33)
        prob_mais_baixos = self.padroes_distribuicao.get(categoria_atual, {}).get('para_mais_baixos', 0.33)
        
        print(f"üîÑ Prob. mais altos: {prob_mais_altos:.1%}")
        print(f"üîÑ Prob. mais baixos: {prob_mais_baixos:.1%}")
        
        # Combinar predi√ß√µes com peso para padr√µes de distribui√ß√£o
        pred_final = (pred_tf * 0.4 + 
                     pred_ensemble['random_forest'] * 0.3 + 
                     pred_ensemble['gradient_boosting'] * 0.3)
        
        # üÜï BOOST baseado em padr√µes de distribui√ß√£o
        fator_boost_altos = 1 + (prob_mais_altos - 0.33) * 2  # Amplifica diferen√ßa da m√©dia
        fator_boost_baixos = 1 + (prob_mais_baixos - 0.33) * 2
        
        # Aplicar boost nos n√∫meros altos (14-25) e baixos (2-13)
        for i in range(25):
            numero = i + 1
            if 14 <= numero <= 25:  # N√∫meros altos
                pred_final[i] *= fator_boost_altos
            elif 2 <= numero <= 13:  # N√∫meros baixos
                pred_final[i] *= fator_boost_baixos
        
        # Selecionar top 15 n√∫meros
        indices_ordenados = np.argsort(pred_final)[::-1]
        numeros_preditos = []
        
        for i in indices_ordenados[:15]:
            numero = i + 1
            confianca = pred_final[i]
            numeros_preditos.append((numero, confianca))
        
        # Estat√≠sticas da predi√ß√£o
        numeros_finais = [num for num, _ in numeros_preditos]
        baixos_pred = [n for n in numeros_finais if 2 <= n <= 13]
        altos_pred = [n for n in numeros_finais if 14 <= n <= 25]
        
        print(f"\nüéØ PREDI√á√ÉO FINAL:")
        print(f"   N√∫meros: {sorted(numeros_finais)}")
        print(f"   Baixos (2-13): {len(baixos_pred)} n√∫meros")
        print(f"   Altos (14-25): {len(altos_pred)} n√∫meros")
        print(f"   Distribui√ß√£o: {self.categorizar_distribuicao(len(baixos_pred), len(altos_pred))}")
        
        return {
            'numeros': numeros_finais,
            'numeros_com_confianca': numeros_preditos,
            'qtd_baixos': len(baixos_pred),
            'qtd_altos': len(altos_pred),
            'distribuicao_predita': self.categorizar_distribuicao(len(baixos_pred), len(altos_pred)),
            'categoria_atual': categoria_atual,
            'prob_mais_altos': prob_mais_altos,
            'prob_mais_baixos': prob_mais_baixos
        }
    
    def executar_sistema_completo(self):
        """Executa o sistema completo"""
        print("üß† SISTEMA NEURAL NETWORK V7.0 - INICIANDO")
        print("="*60)
        
        # Carregar dados
        if not self.carregar_dados_reais():
            return False
        
        # Extrair features
        self.extrair_features_avancadas()
        
        # Treinar modelos
        if not self.treinar_modelos():
            return False
        
        # Gerar predi√ß√£o
        predicao = self.gerar_predicao_inteligente()
        
        if predicao:
            print("\n" + "="*60)
            print("‚úÖ SISTEMA NEURAL V7.0 CONCLU√çDO COM SUCESSO!")
            print("="*60)
            
            return predicao
        
        return False

def main():
    """Fun√ß√£o principal"""
    sistema = SistemaNeuralNetworkV7()
    
    try:
        resultado = sistema.executar_sistema_completo()
        
        if resultado:
            print(f"\nüéØ RESULTADO FINAL:")
            print(f"   N√∫meros sugeridos: {sorted(resultado['numeros'])}")
            print(f"   Confian√ßa baseada em: Padr√µes neurais + Distribui√ß√£o altos/baixos")
            
    except KeyboardInterrupt:
        print("\n‚ùå Execu√ß√£o interrompida pelo usu√°rio")
    except Exception as e:
        print(f"\n‚ùå Erro durante execu√ß√£o: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()